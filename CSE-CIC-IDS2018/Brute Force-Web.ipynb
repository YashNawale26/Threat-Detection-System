{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0983086-6264-47d3-bc5f-3a0ec3dbfaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      "Model Performance Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       293\n",
      "           1       0.98      0.99      0.98       122\n",
      "\n",
      "    accuracy                           0.99       415\n",
      "   macro avg       0.99      0.99      0.99       415\n",
      "weighted avg       0.99      0.99      0.99       415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Dense, Input\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# # Load and prepare data\n",
    "# df = pd.read_csv('Brute Force-Web.csv')\n",
    "\n",
    "# # Separate features and target\n",
    "# X = df.drop('Label', axis=1)  # Assuming 'Label' is the target column\n",
    "# y = df['Label']\n",
    "\n",
    "# # Encode labels\n",
    "# le = LabelEncoder()\n",
    "# y_encoded = le.fit_transform(y)\n",
    "\n",
    "# # Scale features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 1. Random Forest Feature Extraction\n",
    "# def random_forest_feature_importance(X_train, y_train, X_test):\n",
    "#     rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#     rf.fit(X_train, y_train)\n",
    "    \n",
    "#     # Get feature importance scores\n",
    "#     importances = rf.feature_importances_\n",
    "#     feature_indices = np.argsort(importances)[::-1][:10]  # Top 10 features\n",
    "    \n",
    "#     return X_train[:, feature_indices], X_test[:, feature_indices], rf\n",
    "\n",
    "# # 2. LDA Feature Extraction\n",
    "# def lda_feature_extraction(X_train, y_train, X_test):\n",
    "#     lda = LinearDiscriminantAnalysis()\n",
    "#     X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "#     X_test_lda = lda.transform(X_test)\n",
    "    \n",
    "#     return X_train_lda, X_test_lda, lda\n",
    "\n",
    "# # 3. Autoencoder Feature Extraction\n",
    "# def autoencoder_feature_extraction(X_train, X_test):\n",
    "#     input_dim = X_train.shape[1]\n",
    "#     encoding_dim = 10\n",
    "    \n",
    "#     input_layer = Input(shape=(input_dim,))\n",
    "#     encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "#     decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "    \n",
    "#     autoencoder = Model(input_layer, decoded)\n",
    "#     encoder = Model(input_layer, encoded)\n",
    "    \n",
    "#     autoencoder.compile(optimizer='adam', loss='mse')\n",
    "#     autoencoder.fit(X_train, X_train, epochs=50, batch_size=256, shuffle=True, verbose=0)\n",
    "    \n",
    "#     X_train_encoded = encoder.predict(X_train)\n",
    "#     X_test_encoded = encoder.predict(X_test)\n",
    "    \n",
    "#     return X_train_encoded, X_test_encoded, encoder\n",
    "\n",
    "# # Apply feature extraction methods\n",
    "# X_train_rf, X_test_rf, rf_model = random_forest_feature_importance(X_train, y_train, X_test)\n",
    "# X_train_lda, X_test_lda, lda_model = lda_feature_extraction(X_train, y_train, X_test)\n",
    "# X_train_ae, X_test_ae, encoder_model = autoencoder_feature_extraction(X_train, X_test)\n",
    "\n",
    "# # Create ensemble model\n",
    "# def create_ensemble_model():\n",
    "#     rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#     rf_clf.fit(X_train_rf, y_train)\n",
    "#     return rf_clf\n",
    "\n",
    "# ensemble_model = create_ensemble_model()\n",
    "\n",
    "# # Function to predict single log\n",
    "# def predict_log(log_data):\n",
    "#     # Scale the input data\n",
    "#     log_scaled = scaler.transform(log_data)\n",
    "    \n",
    "#     # Extract features using all methods\n",
    "#     log_rf = log_scaled[:, rf_model.feature_importances_.argsort()[::-1][:10]]\n",
    "#     log_lda = lda_model.transform(log_scaled)\n",
    "#     log_ae = encoder_model.predict(log_scaled)\n",
    "    \n",
    "#     # Make prediction using ensemble model\n",
    "#     prediction = ensemble_model.predict(log_rf)\n",
    "    \n",
    "#     return le.inverse_transform(prediction)[0]\n",
    "\n",
    "# # Function to test random log from dataset\n",
    "# def test_random_log():\n",
    "#     # Select random row\n",
    "#     random_idx = np.random.randint(0, len(df))\n",
    "#     random_log = df.iloc[random_idx:random_idx+1].copy()\n",
    "#     actual_label = random_log['Label'].values[0]\n",
    "#     random_log_features = random_log.drop('Label', axis=1)\n",
    "    \n",
    "#     # Make prediction\n",
    "#     predicted_label = predict_log(random_log_features)\n",
    "    \n",
    "#     print(\"Random Log Details:\")\n",
    "#     print(random_log)\n",
    "#     print(\"\\nActual Label:\", actual_label)\n",
    "#     print(\"Predicted Label:\", predicted_label)\n",
    "#     print(\"Attack Detected:\", \"Yes\" if predicted_label == \"Brute Force-Web\" else \"No\")\n",
    "\n",
    "# # Test the model with random log\n",
    "# # test_random_log()\n",
    "\n",
    "# # Space for custom log testing\n",
    "# \"\"\"\n",
    "# # To test your own log, use this format:\n",
    "# custom_log = pd.DataFrame({\n",
    "#     'feature1': [value1],\n",
    "#     'feature2': [value2],\n",
    "#     ...\n",
    "# })\n",
    "# result = predict_log(custom_log)\n",
    "# print(\"Prediction for custom log:\", result)\n",
    "# \"\"\"\n",
    "\n",
    "# # Print model performance metrics\n",
    "# y_pred = ensemble_model.predict(X_test_rf)\n",
    "# print(\"\\nModel Performance Metrics:\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed05ed9a-f324-4075-b823-11f8ad249a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Random Log Details:\n",
      "     Dst Port  Protocol  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
      "436         0         0      112641182             3             0   \n",
      "\n",
      "     TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n",
      "436                0              0.0                0                0   \n",
      "\n",
      "     Fwd Pkt Len Mean  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
      "436               0.0  ...                 0          0.0         0.0   \n",
      "\n",
      "     Active Max  Active Min   Idle Mean   Idle Std    Idle Max    Idle Min  \\\n",
      "436         0.0         0.0  56320591.0  70.710678  56320641.0  56320541.0   \n",
      "\n",
      "                Label  \n",
      "436  Brute Force -Web  \n",
      "\n",
      "[1 rows x 79 columns]\n",
      "\n",
      "Actual Label: Brute Force -Web\n",
      "Predicted Label: Brute Force -Web\n",
      "Attack Detected: No\n"
     ]
    }
   ],
   "source": [
    "# test_random_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ceb172-e587-42f8-ae97-26dc69f704aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brute Force-Web_label_encoder.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the ensemble model\n",
    "dump(ensemble_model, 'Brute Force-Web_ensemble_model.joblib')\n",
    "\n",
    "# Save the scaler\n",
    "dump(scaler, 'Brute Force-Web_scaler.joblib')\n",
    "\n",
    "# Save the label encoder\n",
    "dump(le, 'Brute Force-Web_label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bcd0e6-29c7-4d86-befc-fecc9fc239eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
